{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5XqjxVhTC5bq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda for inference\n"
          ]
        }
      ],
      "source": [
        "# Problem 3\n",
        "\n",
        "# import libraries\n",
        "import numpy as np\n",
        "import torch, os, copy, shutil\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader , random_split\n",
        "from torchvision import models, datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Using {device} for inference')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5BOVl2rGDoPU"
      },
      "outputs": [],
      "source": [
        "# will change later lmao literally right from dhruv's rn lmao sorry\n",
        "# i mean i use google colab so im 90% sure my issue is this right here lol\n",
        "\n",
        "base_dir = \"Cat Vs Dog Dataset\"\n",
        "train_dir = os.path.join(base_dir,\"train\")\n",
        "\n",
        "if not os.path.exists(f\"{train_dir}/cat\"):\n",
        "        os.makedirs(f\"{train_dir}/cat\")\n",
        "        \n",
        "if not os.path.exists(f\"{train_dir}/dog\"):\n",
        "        os.makedirs(f\"{train_dir}/dog\")\n",
        "\n",
        "# sort the cats and dogs into two separate files\n",
        "onlyFilesinTrain = [filename for filename in os.listdir(train_dir) if not os.path.isdir(os.path.join(train_dir,filename))]\n",
        "\n",
        "for filename in onlyFilesinTrain:\n",
        "        \n",
        "        label = filename.split(\".\")[0]\n",
        "        \n",
        "        if(label == \"cat\"):\n",
        "                shutil.move(f\"{train_dir}/{filename}\" , f\"{train_dir}/cat/{filename}\")\n",
        "                \n",
        "        elif(label == \"dog\"):\n",
        "                shutil.move(f\"{train_dir}/{filename}\" , f\"{train_dir}/dog/{filename}\")\n",
        "        \n",
        "        else:\n",
        "                print(\"No Label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PYnRhre4PuI6"
      },
      "outputs": [],
      "source": [
        "# set parameters and loaders\n",
        "batches = 50\n",
        "epochs = 5          \n",
        "classes = 2           # cat and dog\n",
        "\n",
        "data_transform = transforms.Compose( [transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "dataset = datasets.ImageFolder(train_dir,transform=data_transform)\n",
        "size = len(dataset)\n",
        "\n",
        "train_data,test_data = random_split(dataset, [int(0.7*size) , int(0.3*size)] ) # train 70%, test 30%\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batches, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size = batches, shuffle=False)\n",
        "\n",
        "dataset_classes = dataset.classes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NPMSyyU9D_8E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=512, out_features=1000, bias=True)\n",
            "\n",
            "Linear(in_features=512, out_features=2, bias=True)\n"
          ]
        }
      ],
      "source": [
        "# load ResNet18 and evaluate the model\n",
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "print(resnet18.fc)\n",
        "\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features,2) # only need 2 classes (cat and dog)\n",
        "print()\n",
        "print(resnet18.fc)\n",
        "\n",
        "resnet18 = resnet18.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LreTWj36EbDt"
      },
      "outputs": [],
      "source": [
        "# compare true and predicted label\n",
        "def compute_accuracy (model, data_loader, device):\n",
        "\n",
        "    model = model.to(device)\n",
        "    model = model.eval()\n",
        "    \n",
        "    num_correct_prediction = 0\n",
        "    num_total_labels = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(data_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels\n",
        "            \n",
        "            probabilities = resnet18(inputs.to(device))\n",
        "            predicted_class = torch.argmax(probabilities.cpu(), dim=1)\n",
        "            \n",
        "            num_total_labels += labels.size()[0]\n",
        "            num_correct_prediction += (predicted_class == labels).sum()\n",
        "\n",
        "    return num_correct_prediction/num_total_labels * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x8cSkcFwEg7N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "EPOCH: 1\n",
            "\n",
            "Batch: 0/350    Loss: 0.8426664471626282\n",
            "Batch: 50/350    Loss: 0.3809688687324524\n",
            "Batch: 100/350    Loss: 0.30176690220832825\n",
            "Batch: 150/350    Loss: 0.23191529512405396\n",
            "Batch: 200/350    Loss: 0.14254559576511383\n",
            "Batch: 250/350    Loss: 0.17372894287109375\n",
            "Batch: 300/350    Loss: 0.1602909117937088\n",
            "\n",
            "Accuracy: 97.36571502685547%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 2\n",
            "\n",
            "Batch: 0/350    Loss: 0.0874902606010437\n",
            "Batch: 50/350    Loss: 0.08381566405296326\n",
            "Batch: 100/350    Loss: 0.1120864599943161\n",
            "Batch: 150/350    Loss: 0.10752487927675247\n",
            "Batch: 200/350    Loss: 0.1666588932275772\n",
            "Batch: 250/350    Loss: 0.05690792575478554\n",
            "Batch: 300/350    Loss: 0.05321763828396797\n",
            "\n",
            "Accuracy: 98.07428741455078%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 3\n",
            "\n",
            "Batch: 0/350    Loss: 0.13832172751426697\n",
            "Batch: 50/350    Loss: 0.03512366861104965\n",
            "Batch: 100/350    Loss: 0.12975898385047913\n",
            "Batch: 150/350    Loss: 0.10037980228662491\n",
            "Batch: 200/350    Loss: 0.054456695914268494\n",
            "Batch: 250/350    Loss: 0.1143610030412674\n",
            "Batch: 300/350    Loss: 0.05353511869907379\n",
            "\n",
            "Accuracy: 98.54857635498047%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 4\n",
            "\n",
            "Batch: 0/350    Loss: 0.046935081481933594\n",
            "Batch: 50/350    Loss: 0.0691191554069519\n",
            "Batch: 100/350    Loss: 0.030318038538098335\n",
            "Batch: 150/350    Loss: 0.07083399593830109\n",
            "Batch: 200/350    Loss: 0.04433167353272438\n",
            "Batch: 250/350    Loss: 0.12607236206531525\n",
            "Batch: 300/350    Loss: 0.06708745658397675\n",
            "\n",
            "Accuracy: 98.72571563720703%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 5\n",
            "\n",
            "Batch: 0/350    Loss: 0.08009276539087296\n",
            "Batch: 50/350    Loss: 0.11500098556280136\n",
            "Batch: 100/350    Loss: 0.033577218651771545\n",
            "Batch: 150/350    Loss: 0.022963155061006546\n",
            "Batch: 200/350    Loss: 0.05844482406973839\n",
            "Batch: 250/350    Loss: 0.07569650560617447\n",
            "Batch: 300/350    Loss: 0.014699429273605347\n",
            "\n",
            "Accuracy: 98.89714050292969%\n",
            "\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "# train ResNet18 model\n",
        "def train_model (model, data_loader, learning_rate, num_epochs, device):\n",
        "    \n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_weights = copy.deepcopy(model.state_dict())\n",
        "    best_accuracy = 0\n",
        "    \n",
        "    for epochs in range(num_epochs):\n",
        "        \n",
        "        print(f\"\\nEPOCH: {epochs+1}\\n\")\n",
        "      \n",
        "        model.train()\n",
        "        for batch_index, (inputs, labels) in enumerate(data_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)   \n",
        "             \n",
        "            probabilities = model(inputs)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss = nn.functional.cross_entropy(probabilities,labels)\n",
        "                \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            \n",
        "            if (batch_index % 50 == 0) :\n",
        "                print(f\"Batch: {batch_index}/{len(data_loader)}    Loss: {loss}\")\n",
        "            \n",
        "        model.eval()      # evaluate the model\n",
        "        with torch.set_grad_enabled(False):\n",
        "            accuracy = compute_accuracy(model,data_loader,device)\n",
        "            print(f\"\\nAccuracy: {accuracy}%\\n\")\n",
        "            print(\"-----------------------------------\")\n",
        "        if (accuracy > best_accuracy):\n",
        "            best_accuracy = accuracy\n",
        "            best_weights = model.state_dict()\n",
        "    \n",
        "    model.load_state_dict(best_weights)\n",
        "    return model\n",
        "\n",
        "resnet18 = train_model(resnet18,train_loader,0.001,epochs,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hDvk66G6Fmdr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Predicted Class : dog\n",
            "Actual Class : dog\n",
            "\n",
            "Total Accuracy : 98.36000061035156%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# test ResNet18 after training\n",
        "predicted_class18 = torch.empty(0).to(device)\n",
        "true_label_18 = torch.empty(0)\n",
        "\n",
        "resnet18 = resnet18.eval()\n",
        "\n",
        "for batch_index, (inputs, labels) in enumerate(test_loader):\n",
        "\n",
        "    true_label_18 = torch.cat((true_label_18,labels))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        probabilities = resnet18(inputs.to(device))\n",
        "        predicted_class18 = torch.cat((predicted_class18,torch.argmax(probabilities,dim=1)))\n",
        "\n",
        "with torch.no_grad():\n",
        "        prob = resnet18(inputs.to(device))\n",
        "        pred_class = torch.argmax(prob, dim=1)\n",
        "\n",
        "print(f\"\\n\\nPredicted Class : {dataset_classes[int(pred_class[10].item())]}\")\n",
        "print(f\"Actual Class : {dataset_classes[int(labels[10].item())]}\")\n",
        "print(f\"\\nTotal Accuracy : {(compute_accuracy(resnet18,test_loader,device))}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7p7DgisiC2tr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Confusion Matrix for all 10,000 samples:\n",
            "\n",
            "      cat   dog\n",
            "cat  3612    47\n",
            "dog    76  3765\n",
            "\n",
            "Accuracy: 0.983684223221511\n",
            "F-score: 0.9835931721345155\n",
            "Precison: 0.9835315694473212\n",
            "Recall: 0.983684223221511\n"
          ]
        }
      ],
      "source": [
        "# sklearn results - resnet18\n",
        "y_true = true_label_18.to('cpu')\n",
        "y_pred = predicted_class18.to('cpu')\n",
        "\n",
        "class_label = [\"cat\",\"dog\"]\n",
        "\n",
        "confusion = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "cfm = pd.DataFrame(confusion,index=class_label, columns=class_label)\n",
        "print(\"\\n\\nConfusion Matrix for all 10,000 samples:\\n\")\n",
        "print(cfm)\n",
        "\n",
        "tp = np.array([confusion[i][i] for i in range(len(confusion[0]))])\n",
        "fp = np.array([sum(confusion[:,i]) for i in range(len(confusion[0]))]) - tp\n",
        "fn = np.array([sum(confusion[i,:]) for i in range(len(confusion[0]))])  - tp\n",
        "tn = np.array([sum(sum(confusion)) for i in range(len(confusion[0]))]) - tp - fp - fn\n",
        "\n",
        "precision = tp / (fp+tp)\n",
        "recall = tp / (fn+tp)\n",
        "fscore = 2 * (precision * recall)/(precision +recall)\n",
        "accuracy = tp / (fn+tp)\n",
        "\n",
        "# showing average values\n",
        "print(f\"\\nAccuracy: {sum(accuracy)/len(accuracy)}\") \n",
        "print(f\"F-score: {sum(fscore)/len(fscore)}\")\n",
        "print(f\"Precison: {sum(precision)/len(precision)}\")\n",
        "print(f\"Recall: {sum(recall)/len(recall)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
