{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5XqjxVhTC5bq",
        "outputId": "f191c829-98f3-4abd-8915-36670b8833f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda for inference\n"
          ]
        }
      ],
      "source": [
        "# Problem 3 - used VSCode for this Problem\n",
        "\n",
        "# import libraries\n",
        "import numpy as np\n",
        "import torch, os, copy, shutil\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models, datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Using {device} for inference')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5BOVl2rGDoPU"
      },
      "outputs": [],
      "source": [
        "# upload dataset onto VSCode\n",
        "\n",
        "#base_dir = \"Kaggle Dogs vs Cats\"\n",
        "base_dir = \"Cat vs Dog Dataset\"\n",
        "train_dir = os.path.join(base_dir,\"train\")\n",
        "\n",
        "if not os.path.exists(f\"{train_dir}/cat\"):\n",
        "        os.makedirs(f\"{train_dir}/cat\")\n",
        "        \n",
        "if not os.path.exists(f\"{train_dir}/dog\"):\n",
        "        os.makedirs(f\"{train_dir}/dog\")\n",
        "\n",
        "# sort the cats and dogs into two separate files\n",
        "files = [filename for filename in os.listdir(train_dir) if not os.path.isdir(os.path.join(train_dir,filename))]\n",
        "\n",
        "for filename in files:\n",
        "        \n",
        "        label = filename.split(\".\")[0]\n",
        "        \n",
        "        if(label == \"cat\"):\n",
        "                shutil.move(f\"{train_dir}/{filename}\" , f\"{train_dir}/cat/{filename}\")\n",
        "                \n",
        "        elif(label == \"dog\"):\n",
        "                shutil.move(f\"{train_dir}/{filename}\" , f\"{train_dir}/dog/{filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PYnRhre4PuI6"
      },
      "outputs": [],
      "source": [
        "# set parameters and loaders\n",
        "batches = 50\n",
        "epochs = 5          \n",
        "classes = 2           # cat and dog\n",
        "\n",
        "data_transform = transforms.Compose( [transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "dataset = datasets.ImageFolder(train_dir,transform=data_transform)\n",
        "size = len(dataset)\n",
        "\n",
        "train_data,test_data = random_split(dataset, [int(0.7*size) , int(0.3*size)] ) # train 70%, test 30%\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batches, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size = batches, shuffle=False)\n",
        "\n",
        "dataset_classes = dataset.classes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NPMSyyU9D_8E",
        "outputId": "e1f70095-eead-4eb5-c1a0-26ea735a8c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=512, out_features=1000, bias=True)\n",
            "\n",
            "Linear(in_features=512, out_features=2, bias=True)\n"
          ]
        }
      ],
      "source": [
        "# load ResNet18 and evaluate the model\n",
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "print(resnet18.fc)\n",
        "\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features,2) # only need 2 classes (cat and dog)\n",
        "print()\n",
        "print(resnet18.fc)\n",
        "\n",
        "resnet18 = resnet18.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LreTWj36EbDt"
      },
      "outputs": [],
      "source": [
        "# compare true and predicted label\n",
        "def compute_accuracy (model, data_loader, device):\n",
        "\n",
        "    model = model.to(device)\n",
        "    model = model.eval()\n",
        "    \n",
        "    num_correct_prediction = 0\n",
        "    num_total_labels = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(data_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels\n",
        "            \n",
        "            probabilities = model(inputs.to(device))\n",
        "            predicted_class = torch.argmax(probabilities.cpu(), dim=1)\n",
        "            \n",
        "            num_total_labels += labels.size()[0]\n",
        "            num_correct_prediction += (predicted_class == labels).sum()\n",
        "\n",
        "    return num_correct_prediction/num_total_labels * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x8cSkcFwEg7N"
      },
      "outputs": [],
      "source": [
        "# train ResNet18 model\n",
        "def train_model (model, data_loader, learning_rate, num_epochs, device):\n",
        "    \n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_weights = copy.deepcopy(model.state_dict())\n",
        "    best_accuracy = 0\n",
        "    \n",
        "    for epochs in range(num_epochs):\n",
        "        \n",
        "        print(f\"\\nEPOCH: {epochs+1}\\n\")\n",
        "      \n",
        "        model.train()\n",
        "        for batch_index, (inputs, labels) in enumerate(data_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)   \n",
        "             \n",
        "            probabilities = model(inputs)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss = nn.functional.cross_entropy(probabilities,labels)\n",
        "                \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            \n",
        "            if (batch_index % 50 == 0) :\n",
        "                print(f\"Batch: {batch_index}/{len(data_loader)}    Loss: {loss}\")\n",
        "            \n",
        "        model.eval()      # evaluate the model\n",
        "        with torch.set_grad_enabled(False):\n",
        "            accuracy = compute_accuracy(model,data_loader,device)\n",
        "            print(f\"\\nAccuracy: {accuracy}%\\n\")\n",
        "            print(\"-----------------------------------\")\n",
        "        if (accuracy > best_accuracy):\n",
        "            best_accuracy = accuracy\n",
        "            best_weights = model.state_dict()\n",
        "    \n",
        "    model.load_state_dict(best_weights)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v0T5NAMfaa6m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "EPOCH: 1\n",
            "\n",
            "Batch: 0/350    Loss: 0.6471872925758362\n",
            "Batch: 50/350    Loss: 0.31590649485588074\n",
            "Batch: 100/350    Loss: 0.2364652305841446\n",
            "Batch: 150/350    Loss: 0.1781313121318817\n",
            "Batch: 200/350    Loss: 0.15078173577785492\n",
            "Batch: 250/350    Loss: 0.1603356897830963\n",
            "Batch: 300/350    Loss: 0.1370546668767929\n",
            "\n",
            "Accuracy: 97.45143127441406%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 2\n",
            "\n",
            "Batch: 0/350    Loss: 0.17332641780376434\n",
            "Batch: 50/350    Loss: 0.10430306196212769\n",
            "Batch: 100/350    Loss: 0.0916546881198883\n",
            "Batch: 150/350    Loss: 0.04703783988952637\n",
            "Batch: 200/350    Loss: 0.23093071579933167\n",
            "Batch: 250/350    Loss: 0.05816836282610893\n",
            "Batch: 300/350    Loss: 0.09287645667791367\n",
            "\n",
            "Accuracy: 98.02857208251953%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 3\n",
            "\n",
            "Batch: 0/350    Loss: 0.1497117578983307\n",
            "Batch: 50/350    Loss: 0.06633371114730835\n",
            "Batch: 100/350    Loss: 0.08906285464763641\n",
            "Batch: 150/350    Loss: 0.08916011452674866\n",
            "Batch: 200/350    Loss: 0.11589488387107849\n",
            "Batch: 250/350    Loss: 0.04890846088528633\n",
            "Batch: 300/350    Loss: 0.054572030901908875\n",
            "\n",
            "Accuracy: 98.3028564453125%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 4\n",
            "\n",
            "Batch: 0/350    Loss: 0.04062769562005997\n",
            "Batch: 50/350    Loss: 0.029276235029101372\n",
            "Batch: 100/350    Loss: 0.040201738476753235\n",
            "Batch: 150/350    Loss: 0.012425100430846214\n",
            "Batch: 200/350    Loss: 0.0887703225016594\n",
            "Batch: 250/350    Loss: 0.03476763889193535\n",
            "Batch: 300/350    Loss: 0.08514725416898727\n",
            "\n",
            "Accuracy: 98.61714172363281%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 5\n",
            "\n",
            "Batch: 0/350    Loss: 0.1020747721195221\n",
            "Batch: 50/350    Loss: 0.03112439624965191\n",
            "Batch: 100/350    Loss: 0.10251899063587189\n",
            "Batch: 150/350    Loss: 0.08433432877063751\n",
            "Batch: 200/350    Loss: 0.016479695215821266\n",
            "Batch: 250/350    Loss: 0.0122714564204216\n",
            "Batch: 300/350    Loss: 0.07908990979194641\n",
            "\n",
            "Accuracy: 98.61714172363281%\n",
            "\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "resnet18 = train_model(resnet18,train_loader,0.001,epochs,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hDvk66G6Fmdr",
        "outputId": "04c230f5-4117-4403-c3b6-0f681b067bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Predicted Class: dog\n",
            "Actual Class: dog\n",
            "\n",
            "Total Accuracy: 98.54666900634766%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# test ResNet18 after training\n",
        "predicted_class18 = torch.empty(0).to(device)\n",
        "true_label_18 = torch.empty(0)\n",
        "\n",
        "resnet18 = resnet18.eval()\n",
        "\n",
        "for batch_index, (inputs, labels) in enumerate(test_loader):\n",
        "\n",
        "    true_label_18 = torch.cat((true_label_18,labels))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        probabilities = resnet18(inputs.to(device))\n",
        "        predicted_class18 = torch.cat((predicted_class18,torch.argmax(probabilities,dim=1)))\n",
        "\n",
        "with torch.no_grad():\n",
        "        prob = resnet18(inputs.to(device))\n",
        "        pred_class = torch.argmax(prob, dim=1)\n",
        "\n",
        "print(f\"\\n\\nPredicted Class: {dataset_classes[int(pred_class[10].item())]}\")\n",
        "print(f\"Actual Class: {dataset_classes[int(labels[10].item())]}\")\n",
        "print(f\"\\nTotal Accuracy: {(compute_accuracy(resnet18,test_loader,device))}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7p7DgisiC2tr",
        "outputId": "e90e2a7d-55eb-498b-a54e-6b3735e21f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Confusion Matrix for ResNet18:\n",
            "\n",
            "      cat   dog\n",
            "cat  3733    26\n",
            "dog    83  3658\n",
            "\n",
            "Accuracy: 0.9854483428491214\n",
            "F-score: 0.9854652131879854\n",
            "Precison: 0.9855959648727457\n",
            "Recall: 0.9854483428491214\n"
          ]
        }
      ],
      "source": [
        "# sklearn results - resnet18\n",
        "y_true = true_label_18.to('cpu')\n",
        "y_pred = predicted_class18.to('cpu')\n",
        "\n",
        "class_label = [\"cat\",\"dog\"]\n",
        "\n",
        "confusion = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "cfm = pd.DataFrame(confusion,index=class_label, columns=class_label)\n",
        "print(\"\\n\\nConfusion Matrix for ResNet18:\\n\")\n",
        "print(cfm)\n",
        "\n",
        "tp = np.array([confusion[i][i] for i in range(len(confusion[0]))])\n",
        "fp = np.array([sum(confusion[:,i]) for i in range(len(confusion[0]))]) - tp\n",
        "fn = np.array([sum(confusion[i,:]) for i in range(len(confusion[0]))])  - tp\n",
        "tn = np.array([sum(sum(confusion)) for i in range(len(confusion[0]))]) - tp - fp - fn\n",
        "\n",
        "precision = tp / (fp+tp)\n",
        "recall = tp / (fn+tp)\n",
        "fscore = 2 * (precision * recall)/(precision +recall)\n",
        "accuracy = tp / (fn+tp)\n",
        "\n",
        "# showing average values\n",
        "print(f\"\\nAccuracy: {sum(accuracy)/len(accuracy)}\") \n",
        "print(f\"F-score: {sum(fscore)/len(fscore)}\")\n",
        "print(f\"Precison: {sum(precision)/len(precision)}\")\n",
        "print(f\"Recall: {sum(recall)/len(recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "URQf-2vkR_uH",
        "outputId": "fa2f0f72-49af-441f-b8db-9e3c42d7525a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=2048, out_features=1000, bias=True)\n",
            "\n",
            "Linear(in_features=2048, out_features=2, bias=True)\n",
            "\n",
            "EPOCH: 1\n",
            "\n",
            "Batch: 0/350    Loss: 0.6808891296386719\n",
            "Batch: 50/350    Loss: 0.5249034762382507\n",
            "Batch: 100/350    Loss: 0.4600221514701843\n",
            "Batch: 150/350    Loss: 0.3469408452510834\n",
            "Batch: 200/350    Loss: 0.34465453028678894\n",
            "Batch: 250/350    Loss: 0.2929426431655884\n",
            "Batch: 300/350    Loss: 0.2628886103630066\n",
            "\n",
            "Accuracy: 97.84571838378906%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 2\n",
            "\n",
            "Batch: 0/350    Loss: 0.25009748339653015\n",
            "Batch: 50/350    Loss: 0.21329748630523682\n",
            "Batch: 100/350    Loss: 0.2063545286655426\n",
            "Batch: 150/350    Loss: 0.1599852740764618\n",
            "Batch: 200/350    Loss: 0.14842699468135834\n",
            "Batch: 250/350    Loss: 0.11750787496566772\n",
            "Batch: 300/350    Loss: 0.1434956043958664\n",
            "\n",
            "Accuracy: 98.34285736083984%\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "EPOCH: 3\n",
            "\n",
            "Batch: 0/350    Loss: 0.10729196667671204\n",
            "Batch: 50/350    Loss: 0.11569489538669586\n",
            "Batch: 100/350    Loss: 0.12617813050746918\n",
            "Batch: 150/350    Loss: 0.10885738581418991\n",
            "Batch: 200/350    Loss: 0.11068069189786911\n",
            "Batch: 250/350    Loss: 0.10521908849477768\n",
            "Batch: 300/350    Loss: 0.09954066574573517\n",
            "\n",
            "Accuracy: 98.55428314208984%\n",
            "\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "epoch = 3 # ResNet50 has more layers than ResNet18, so I reduced the number of epochs\n",
        "\n",
        "# load and train ResNet50 model\n",
        "resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "print(resnet50.fc)\n",
        "\n",
        "# we only need 2 classes need to cahnge ouput layer\n",
        "resnet50.fc = nn.Linear(resnet50.fc.in_features,2)\n",
        "print()\n",
        "print(resnet50.fc)\n",
        "\n",
        "resnet50 = resnet50.to(device)\n",
        "resnet50 = train_model(resnet50,train_loader,0.001,epoch,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HPsYhoX1SJcT",
        "outputId": "87d04457-4caf-4739-81f6-4b7396ec9d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Predicted Class: dog\n",
            "Actual Class: dog\n",
            "\n",
            "Total Accuracy: 98.41333770751953%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# testing ResNet50 model\n",
        "predicted_class50 = torch.empty(0).to(device)\n",
        "true_label50 = torch.empty(0)\n",
        "\n",
        "resnet50 = resnet50.eval()\n",
        "\n",
        "for batch_index, (inputs, labels) in enumerate(test_loader):\n",
        "\n",
        "    true_label50 = torch.cat((true_label50,labels))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        probabilities = resnet50(inputs.to(device))\n",
        "        predicted_class50 = torch.cat((predicted_class50,torch.argmax(probabilities,dim=1)))\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "        prob = resnet50(inputs.to(device))\n",
        "        pred_class = torch.argmax(prob, dim=1)\n",
        "\n",
        "print(f\"\\n\\nPredicted Class: {dataset_classes[int(pred_class[1].item())]}\")\n",
        "print(f\"Actual Class: {dataset_classes[int(labels[1].item())]}\")\n",
        "print(f\"\\nTotal Accuracy: {(compute_accuracy(resnet50,test_loader,device))}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "auIpAaBtSLS0",
        "outputId": "fd71a54f-9f37-4b33-ff60-8773d7b437e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Confusion Matrix for ResNet50:\n",
            "\n",
            "      cat   dog\n",
            "cat  3715    44\n",
            "dog    75  3666\n",
            "\n",
            "Accuracy: 0.9841233218836674\n",
            "F-score: 0.9841326560445718\n",
            "Precison: 0.9841756217596314\n",
            "Recall: 0.9841233218836674\n"
          ]
        }
      ],
      "source": [
        "# sklearn results\n",
        "\n",
        "y_true = true_label50.to('cpu')\n",
        "y_pred = predicted_class50.to('cpu')\n",
        "\n",
        "confusion = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "class_label = [\"cat\",\"dog\"]\n",
        "\n",
        "cfm = pd.DataFrame(confusion,index=class_label,columns=class_label)\n",
        "print(\"\\n\\nConfusion Matrix for ResNet50:\\n\")\n",
        "print(cfm)\n",
        "\n",
        "tp = np.array([confusion[i][i] for i in range(len(confusion[0]))])\n",
        "fp = np.array([sum(confusion[:,i]) for i in range(len(confusion[0]))]) - tp\n",
        "fn = np.array([sum(confusion[i,:]) for i in range(len(confusion[0]))])  - tp\n",
        "tn = np.array([sum(sum(confusion)) for i in range(len(confusion[0]))]) - tp - fp - fn\n",
        "\n",
        "precision = tp / (fp+tp)\n",
        "recall = tp / (fn+tp)\n",
        "fscore = 2 * (precision * recall)/(precision +recall)\n",
        "accuracy = tp / (fn+tp)\n",
        "\n",
        "# showing average values\n",
        "print(f\"\\nAccuracy: {sum(accuracy)/len(accuracy)}\") \n",
        "print(f\"F-score: {sum(fscore)/len(fscore)}\")\n",
        "print(f\"Precison: {sum(precision)/len(precision)}\")\n",
        "print(f\"Recall: {sum(recall)/len(recall)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
