{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {DEVICE} for inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Settings #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "NUM_INPUTS = 1*28*28 # grayscale (1-channel) 28*28 picture\n",
    "NUM_CLASSES = 10 # digits 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load MNIST Dataset #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"dataset\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform= transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"dataset\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform= transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "CLASSES = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Linear(in_features=512, out_features=1000, bias=True)\n",
      "\n",
      "Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Linear(in_features=512, out_features=10, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "print(resnet18.conv1)\n",
    "print(resnet18.fc)\n",
    "\n",
    "# we only need 10 classes need to cahnge ouput layer\n",
    "# we also need to chnage so it takes 1 cahnnel instead of three channels\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features,NUM_CLASSES)\n",
    "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "print()\n",
    "print(resnet18.conv1)\n",
    "print(resnet18.fc)\n",
    "\n",
    "# Make sure to send our model to GPU if available\n",
    "resnet18 = resnet18.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare True Label w/ Predicted Label #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (model, data_loader, device):\n",
    "    model = model.to(device)\n",
    "    model = model.eval() # put the model to evaultion mode\n",
    "    \n",
    "    num_correct_prediction = 0\n",
    "    num_total_labels = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            probabilities = resnet18(inputs.to(DEVICE))\n",
    "            predicted_class = torch.argmax(probabilities, dim=1) # Class predicted by model\n",
    "            \n",
    "            num_total_labels += labels.size()[0]\n",
    "            num_correct_prediction += (predicted_class == labels).sum()\n",
    "\n",
    "    return num_correct_prediction/num_total_labels * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test w/o training ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Num : 4\n",
      "Actual Num : 4\n",
      "\n",
      "Total Accuracy on test data : 13.180 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_index, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "    inputs = inputs\n",
    "    labels = labels\n",
    "    break\n",
    "    \n",
    "\n",
    "    \n",
    "img = np.transpose(inputs[4], axes=(1, 2, 0))\n",
    "img = np.squeeze(img.numpy(), axis=2)\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show\n",
    "\n",
    "\n",
    "\n",
    "resnet18 = resnet18.eval()\n",
    "\n",
    "with torch.no_grad(): # Save Performance when evaluting or prediciting\n",
    "    probabilities = resnet18(inputs.to(DEVICE))\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "print(\"Predicted Num : {:d}\".format(predicted_class[4]))\n",
    "print(\"Actual Num : {:d}\".format(labels[4]))\n",
    "print(\"\\nTotal Accuracy on test data : {:.3f} %\".format(compute_accuracy(resnet18,test_loader,DEVICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model (model, data_loader, learning_rate, num_epochs, device):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epochs in range(num_epochs):\n",
    "        \n",
    "        print(\"EPOCH : {0}/{1}\".format(epochs+1,num_epochs))\n",
    "        print(\"-\"*30)\n",
    "        \n",
    "        # train first\n",
    "        model.train()\n",
    "        for batch_index, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)   \n",
    "             \n",
    "            probabilities = resnet18(inputs)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = nn.functional.cross_entropy(probabilities,labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            \n",
    "            if (batch_index % 50 == 0) :\n",
    "                print(\"BATCH : {:3d}/{:3d} | LOSS : {:.3f} \".format(batch_index,len(data_loader),loss))\n",
    "            \n",
    "        \n",
    "        # evalute\n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            accuracy = compute_accuracy(model,data_loader,DEVICE)\n",
    "            print(\"\\nTotal Accuracy On Training Data : {:.3f} %\".format(accuracy))\n",
    "        \n",
    "        # Save best weights\n",
    "        if (accuracy > best_accuracy):\n",
    "            best_accuracy = accuracy\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print(\"Elapsed Time : {:.0f} min {:.0f} sec\\n\".format((time.time() - start_time)/60 , (time.time() - start_time)%60)) \n",
    "    \n",
    "    print(\"\\nTotal Time : {:.0f} min {:.0f} sec\".format((time.time() - start_time)/60 , (time.time() - start_time)%60))\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 2.657 \n",
      "BATCH :  50/469 | LOSS : 1.941 \n",
      "BATCH : 100/469 | LOSS : 1.517 \n",
      "BATCH : 150/469 | LOSS : 1.221 \n",
      "BATCH : 200/469 | LOSS : 1.039 \n",
      "BATCH : 250/469 | LOSS : 0.921 \n",
      "BATCH : 300/469 | LOSS : 0.570 \n",
      "BATCH : 350/469 | LOSS : 0.590 \n",
      "BATCH : 400/469 | LOSS : 0.471 \n",
      "BATCH : 450/469 | LOSS : 0.544 \n",
      "\n",
      "Total Accuracy On Training Data : 88.393 %\n",
      "Elapsed Time : 0 min 21 sec\n",
      "\n",
      "EPOCH : 2/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.496 \n",
      "BATCH :  50/469 | LOSS : 0.370 \n",
      "BATCH : 100/469 | LOSS : 0.302 \n",
      "BATCH : 150/469 | LOSS : 0.273 \n",
      "BATCH : 200/469 | LOSS : 0.320 \n",
      "BATCH : 250/469 | LOSS : 0.312 \n",
      "BATCH : 300/469 | LOSS : 0.241 \n",
      "BATCH : 350/469 | LOSS : 0.283 \n",
      "BATCH : 400/469 | LOSS : 0.230 \n",
      "BATCH : 450/469 | LOSS : 0.273 \n",
      "\n",
      "Total Accuracy On Training Data : 93.930 %\n",
      "Elapsed Time : 1 min 40 sec\n",
      "\n",
      "EPOCH : 3/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.182 \n",
      "BATCH :  50/469 | LOSS : 0.301 \n",
      "BATCH : 100/469 | LOSS : 0.250 \n",
      "BATCH : 150/469 | LOSS : 0.193 \n",
      "BATCH : 200/469 | LOSS : 0.283 \n",
      "BATCH : 250/469 | LOSS : 0.144 \n",
      "BATCH : 300/469 | LOSS : 0.128 \n",
      "BATCH : 350/469 | LOSS : 0.168 \n",
      "BATCH : 400/469 | LOSS : 0.124 \n",
      "BATCH : 450/469 | LOSS : 0.316 \n",
      "\n",
      "Total Accuracy On Training Data : 95.660 %\n",
      "Elapsed Time : 1 min 0 sec\n",
      "\n",
      "EPOCH : 4/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.203 \n",
      "BATCH :  50/469 | LOSS : 0.154 \n",
      "BATCH : 100/469 | LOSS : 0.119 \n",
      "BATCH : 150/469 | LOSS : 0.118 \n",
      "BATCH : 200/469 | LOSS : 0.170 \n",
      "BATCH : 250/469 | LOSS : 0.150 \n",
      "BATCH : 300/469 | LOSS : 0.212 \n",
      "BATCH : 350/469 | LOSS : 0.071 \n",
      "BATCH : 400/469 | LOSS : 0.262 \n",
      "BATCH : 450/469 | LOSS : 0.185 \n",
      "\n",
      "Total Accuracy On Training Data : 96.643 %\n",
      "Elapsed Time : 1 min 20 sec\n",
      "\n",
      "EPOCH : 5/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.216 \n",
      "BATCH :  50/469 | LOSS : 0.121 \n",
      "BATCH : 100/469 | LOSS : 0.058 \n",
      "BATCH : 150/469 | LOSS : 0.201 \n",
      "BATCH : 200/469 | LOSS : 0.162 \n",
      "BATCH : 250/469 | LOSS : 0.080 \n",
      "BATCH : 300/469 | LOSS : 0.076 \n",
      "BATCH : 350/469 | LOSS : 0.255 \n",
      "BATCH : 400/469 | LOSS : 0.172 \n",
      "BATCH : 450/469 | LOSS : 0.060 \n",
      "\n",
      "Total Accuracy On Training Data : 97.258 %\n",
      "Elapsed Time : 2 min 40 sec\n",
      "\n",
      "EPOCH : 6/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.184 \n",
      "BATCH :  50/469 | LOSS : 0.164 \n",
      "BATCH : 100/469 | LOSS : 0.207 \n",
      "BATCH : 150/469 | LOSS : 0.119 \n",
      "BATCH : 200/469 | LOSS : 0.134 \n",
      "BATCH : 250/469 | LOSS : 0.078 \n",
      "BATCH : 300/469 | LOSS : 0.111 \n",
      "BATCH : 350/469 | LOSS : 0.052 \n",
      "BATCH : 400/469 | LOSS : 0.215 \n",
      "BATCH : 450/469 | LOSS : 0.076 \n",
      "\n",
      "Total Accuracy On Training Data : 97.747 %\n",
      "Elapsed Time : 2 min 0 sec\n",
      "\n",
      "EPOCH : 7/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.092 \n",
      "BATCH :  50/469 | LOSS : 0.059 \n",
      "BATCH : 100/469 | LOSS : 0.104 \n",
      "BATCH : 150/469 | LOSS : 0.100 \n",
      "BATCH : 200/469 | LOSS : 0.116 \n",
      "BATCH : 250/469 | LOSS : 0.043 \n",
      "BATCH : 300/469 | LOSS : 0.119 \n",
      "BATCH : 350/469 | LOSS : 0.080 \n",
      "BATCH : 400/469 | LOSS : 0.070 \n",
      "BATCH : 450/469 | LOSS : 0.159 \n",
      "\n",
      "Total Accuracy On Training Data : 98.067 %\n",
      "Elapsed Time : 2 min 21 sec\n",
      "\n",
      "EPOCH : 8/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.082 \n",
      "BATCH :  50/469 | LOSS : 0.065 \n",
      "BATCH : 100/469 | LOSS : 0.071 \n",
      "BATCH : 150/469 | LOSS : 0.110 \n",
      "BATCH : 200/469 | LOSS : 0.104 \n",
      "BATCH : 250/469 | LOSS : 0.075 \n",
      "BATCH : 300/469 | LOSS : 0.096 \n",
      "BATCH : 350/469 | LOSS : 0.065 \n",
      "BATCH : 400/469 | LOSS : 0.099 \n",
      "BATCH : 450/469 | LOSS : 0.076 \n",
      "\n",
      "Total Accuracy On Training Data : 98.307 %\n",
      "Elapsed Time : 3 min 41 sec\n",
      "\n",
      "EPOCH : 9/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.110 \n",
      "BATCH :  50/469 | LOSS : 0.050 \n",
      "BATCH : 100/469 | LOSS : 0.078 \n",
      "BATCH : 150/469 | LOSS : 0.104 \n",
      "BATCH : 200/469 | LOSS : 0.072 \n",
      "BATCH : 250/469 | LOSS : 0.069 \n",
      "BATCH : 300/469 | LOSS : 0.063 \n",
      "BATCH : 350/469 | LOSS : 0.071 \n",
      "BATCH : 400/469 | LOSS : 0.028 \n",
      "BATCH : 450/469 | LOSS : 0.027 \n",
      "\n",
      "Total Accuracy On Training Data : 98.553 %\n",
      "Elapsed Time : 3 min 1 sec\n",
      "\n",
      "EPOCH : 10/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.084 \n",
      "BATCH :  50/469 | LOSS : 0.087 \n",
      "BATCH : 100/469 | LOSS : 0.075 \n",
      "BATCH : 150/469 | LOSS : 0.029 \n",
      "BATCH : 200/469 | LOSS : 0.099 \n",
      "BATCH : 250/469 | LOSS : 0.024 \n",
      "BATCH : 300/469 | LOSS : 0.076 \n",
      "BATCH : 350/469 | LOSS : 0.127 \n",
      "BATCH : 400/469 | LOSS : 0.130 \n",
      "BATCH : 450/469 | LOSS : 0.076 \n",
      "\n",
      "Total Accuracy On Training Data : 98.723 %\n",
      "Elapsed Time : 3 min 21 sec\n",
      "\n",
      "\n",
      "Total Time : 3 min 21 sec\n"
     ]
    }
   ],
   "source": [
    "resnet18 = train_model(resnet18,train_loader,LEARNING_RATE,NUM_EPOCHS,DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test w/ Training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Num : 7\n",
      "Actual Num : 7\n",
      "\n",
      "Total Accuracy on test data : 97.380 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "features = torch.empty(0)\n",
    "true_label = torch.empty(0)\n",
    "\n",
    "for batch_index, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "    features = torch.cat((features,inputs))\n",
    "    true_label = torch.cat((true_label,labels))\n",
    "    \n",
    "img = np.transpose(features[0], axes=(1, 2, 0))\n",
    "img = np.squeeze(img.numpy(), axis=2)\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show\n",
    "\n",
    "\n",
    "resnet18 = resnet18.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    probabilities = resnet18(features.to(DEVICE))\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "print(\"Predicted Num : {:.0f}\".format(predicted_class[0]))\n",
    "print(\"Actual Num : {:.0f}\".format(true_label[0]))\n",
    "\n",
    "print(\"\\nTotal Accuracy on test data : {:.3f} %\".format(compute_accuracy(resnet18,test_loader,DEVICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix :-\n",
      "|           |   0 - zero |   1 - one |   2 - two |   3 - three |   4 - four |   5 - five |   6 - six |   7 - seven |   8 - eight |   9 - nine |\n",
      "|:----------|-----------:|----------:|----------:|------------:|-----------:|-----------:|----------:|------------:|------------:|-----------:|\n",
      "| 0 - zero  |        961 |         0 |         4 |           1 |          2 |          3 |         4 |           0 |           5 |          0 |\n",
      "| 1 - one   |          0 |      1125 |         3 |           1 |          0 |          0 |         2 |           1 |           3 |          0 |\n",
      "| 2 - two   |          3 |         0 |      1001 |          13 |          1 |          0 |         2 |           3 |           9 |          0 |\n",
      "| 3 - three |          0 |         0 |         5 |         979 |          0 |          9 |         0 |           8 |           7 |          2 |\n",
      "| 4 - four  |          0 |         2 |         0 |           0 |        957 |          0 |         7 |           1 |           1 |         14 |\n",
      "| 5 - five  |          2 |         0 |         0 |           4 |          2 |        866 |         2 |           3 |           7 |          6 |\n",
      "| 6 - six   |          3 |         4 |         3 |           0 |          3 |          7 |       936 |           0 |           2 |          0 |\n",
      "| 7 - seven |          0 |         1 |        14 |           1 |          3 |          0 |         0 |        1001 |           0 |          8 |\n",
      "| 8 - eight |          5 |         1 |         5 |           5 |          3 |          5 |         1 |           2 |         942 |          5 |\n",
      "| 9 - nine  |          3 |         1 |         2 |           6 |          6 |          8 |         1 |           6 |           6 |        970 |\n",
      "\n",
      "Performance Matrix:-\n",
      "|           |   Precison |   Recall |   F-score |   Accuracy |\n",
      "|:----------|-----------:|---------:|----------:|-----------:|\n",
      "| 0 - zero  |    98.3623 |  98.0612 |   98.2115 |    98.0612 |\n",
      "| 1 - one   |    99.2063 |  99.1189 |   99.1626 |    99.1189 |\n",
      "| 2 - two   |    96.5284 |  96.9961 |   96.7617 |    96.9961 |\n",
      "| 3 - three |    96.9307 |  96.9307 |   96.9307 |    96.9307 |\n",
      "| 4 - four  |    97.9529 |  97.4542 |   97.7029 |    97.4542 |\n",
      "| 5 - five  |    96.4365 |  97.0852 |   96.7598 |    97.0852 |\n",
      "| 6 - six   |    98.0105 |  97.7035 |   97.8568 |    97.7035 |\n",
      "| 7 - seven |    97.6585 |  97.3735 |   97.5158 |    97.3735 |\n",
      "| 8 - eight |    95.9267 |  96.7146 |   96.319  |    96.7146 |\n",
      "| 9 - nine  |    96.5174 |  96.1348 |   96.3257 |    96.1348 |\n",
      "| Average   |    97.353  |  97.3573 |   97.3547 |    97.3573 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "LABELS = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "true_label = true_label.to('cpu')\n",
    "predicted_label = predicted_class.to('cpu')\n",
    "\n",
    "cf_matrix = confusion_matrix(true_label,predicted_label)\n",
    "\n",
    "df = pd.DataFrame(cf_matrix, index = CLASSES, columns = CLASSES)\n",
    "\n",
    "num_correct = [cf_matrix[i][i] for i in range(len(cf_matrix[0]))]\n",
    "\n",
    "print(\"\\nConfusion Matrix :-\")\n",
    "print(df.to_markdown())\n",
    "\n",
    "matrix = precision_recall_fscore_support(true_label,predicted_label,labels=LABELS)\n",
    "total_label = matrix[:][len(matrix)-1]\n",
    "accuracy = num_correct / total_label * 100\n",
    "df_matrix = pd.DataFrame(np.array(matrix).T[:,:-1]*100, index = CLASSES, columns = [\"Precison\",\"Recall\",\"F-score\"])\n",
    "df_matrix[\"Accuracy\"] = accuracy\n",
    "df_matrix.loc[\"Average\"] = df_matrix.mean(axis=0) \n",
    "\n",
    "\n",
    "print(\"\\nPerformance Matrix:-\")\n",
    "print(df_matrix.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Matrix:-\n",
      "|           |   Precison |   Recall |   F-score |   Accuracy |\n",
      "|:----------|-----------:|---------:|----------:|-----------:|\n",
      "| 0 - zero  |    98.3623 |  98.0612 |   98.2115 |    98.0612 |\n",
      "| 1 - one   |    99.2063 |  99.1189 |   99.1626 |    99.1189 |\n",
      "| 2 - two   |    96.5284 |  96.9961 |   96.7617 |    96.9961 |\n",
      "| 3 - three |    96.9307 |  96.9307 |   96.9307 |    96.9307 |\n",
      "| 4 - four  |    97.9529 |  97.4542 |   97.7029 |    97.4542 |\n",
      "| 5 - five  |    96.4365 |  97.0852 |   96.7598 |    97.0852 |\n",
      "| 6 - six   |    98.0105 |  97.7035 |   97.8568 |    97.7035 |\n",
      "| 7 - seven |    97.6585 |  97.3735 |   97.5158 |    97.3735 |\n",
      "| 8 - eight |    95.9267 |  96.7146 |   96.319  |    96.7146 |\n",
      "| 9 - nine  |    96.5174 |  96.1348 |   96.3257 |    96.1348 |\n",
      "| Average   |    97.353  |  97.3573 |   97.3547 |    97.3573 |\n"
     ]
    }
   ],
   "source": [
    "TP = np.array([cf_matrix[i][i] for i in range(len(cf_matrix[0]))])\n",
    "\n",
    "F = np.array([sum(cf_matrix[:,i]) for i in range(len(cf_matrix[0]))])\n",
    "FP = F - TP\n",
    "\n",
    "T = np.array([sum(cf_matrix[i,:]) for i in range(len(cf_matrix[0]))])\n",
    "FN = T - TP\n",
    "\n",
    "TN = np.array([sum(sum(cf_matrix)) for i in range(len(cf_matrix[0]))]) - TP - FP - FN\n",
    "\n",
    "\n",
    "precision = TP / (FP+TP)\n",
    "recall = TP / (FN+TP)\n",
    "f_score = 2 * (precision*recall)/(precision+recall)\n",
    "accuracy = TP / T\n",
    "\n",
    "matrix  = [precision,recall,f_score,accuracy]\n",
    "\n",
    "df_matrix = pd.DataFrame(np.array(matrix).T*100, index = CLASSES, columns = [\"Precison\",\"Recall\",\"F-score\",\"Accuracy\"])\n",
    "df_matrix.loc[\"Average\"] = df_matrix.mean(axis=0) \n",
    "\n",
    "\n",
    "print(\"\\nPerformance Matrix:-\")\n",
    "print(df_matrix.to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
