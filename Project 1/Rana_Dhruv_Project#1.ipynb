{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dhruv Rana #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "Predicted for data\\basketball1.jpg : basketball\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted for data\\basketball2.jpg : basketball\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted for data\\cannon1.jpg : cannon\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted for data\\cannon2.jpg : cannon\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted for data\\golfcart1.jpg : golfcart\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted for data\\golfcart2.jpg : golfcart\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted for data\\otter1.JPG : otter\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted for data\\otter2.jpg : otter\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicted for data\\vendingmachine1.jpg : vending_machine\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted for data\\vendingmachine2.jpg : vending_machine\n",
      "\n",
      "Confusion Matrix :-\n",
      "                 basketball  cannon  golfcart  otter  vending_machine\n",
      "basketball                2       0         0      0                0\n",
      "cannon                    0       2         0      0                0\n",
      "golfcart                  0       0         2      0                0\n",
      "otter                     0       0         0      2                0\n",
      "vending_machine           0       0         0      0                2\n",
      "\n",
      "accuray : 1.0\n",
      "precison : 1.0\n",
      "recall : 1.0\n",
      "f-score : 1.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.resnet import preprocess_input, decode_predictions\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "# Using my GPU to accelrate the results\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# sorted alphabatically\n",
    "true_label = ['vending_machine' , 'vending_machine', 'golfcart', 'golfcart' , 'otter', 'otter' , 'basketball' , 'basketball',\n",
    "              'cannon','cannon']\n",
    "true_label = sorted (true_label)\n",
    "\n",
    "label = true_label[::2]\n",
    "\n",
    "predicted_label = []\n",
    "\n",
    "# sorted alphabatically\n",
    "# place all image in data folder\n",
    "images = glob.glob('data\\\\*.jpg')\n",
    "images = sorted(images)\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "if(len(tf.config.experimental.list_physical_devices('GPU')) !=0 ):\n",
    "    with tf.device('/GPU:0'):\n",
    "\n",
    "        for filename in images :\n",
    "            img = load_img(filename, target_size=(224, 224))\n",
    "            img_arr = img_to_array(img)\n",
    "            img_batch = np.expand_dims(img_arr, axis=0)\n",
    "            img_processed = preprocess_input(img_batch)\n",
    "\n",
    "            prediction = model.predict(img_processed)\n",
    "            prediction = np.array(decode_predictions(prediction,top=3))\n",
    "            \n",
    "            predicted_label.append(prediction[0,0,1])\n",
    "            print('Predicted for ' + filename + ' :', prediction[0,0,1])\n",
    "           \n",
    "            \n",
    "else :\n",
    "\n",
    "    for filename in images :\n",
    "        img = load_img(filename, target_size=(224, 224))\n",
    "        img_arr = img_to_array(img)\n",
    "        img_batch = np.expand_dims(img_arr, axis=0)\n",
    "        img_processed = preprocess_input(img_batch)\n",
    "\n",
    "        prediction = model.predict(img_processed)\n",
    "        prediction = np.array(decode_predictions(prediction,top=1))\n",
    "            \n",
    "        predicted_label.append(prediction[0,0,1])\n",
    "        print('Prediction for ' + filename + ' :', prediction[0,0,1])\n",
    "\n",
    "cf_matrix = confusion_matrix(true_label,predicted_label)\n",
    "\n",
    "df = pd.DataFrame(cf_matrix, index = label, columns=label)\n",
    "print(\"\\nConfusion Matrix :-\")\n",
    "print(df)\n",
    "\n",
    "accuracy = accuracy_score(true_label,predicted_label)\n",
    "precison = precision_score(true_label,predicted_label,labels=label, average='micro')\n",
    "recall = recall_score(true_label,predicted_label,labels=label, average='micro')\n",
    "f_score = f1_score(true_label,predicted_label,labels=label, average='micro')\n",
    "\n",
    "print (\"\\naccuray : {0}\".format(accuracy))\n",
    "print (\"precison : {0}\".format(precison))\n",
    "print (\"recall : {0}\".format(recall))\n",
    "print (\"f-score : {0}\".format(f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {DEVICE} for inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Settings #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "NUM_INPUTS = 1*28*28 # grayscale (1-channel) 28*28 picture\n",
    "NUM_CLASSES = 10 # digits 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load MNIST Dataset #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"dataset\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform= transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"dataset\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform= transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "CLASSES = train_data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change Fully Connected Layer ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "print(resnet18.conv1)\n",
    "print(resnet18.fc)\n",
    "\n",
    "# we only need 10 classes need to cahnge ouput layer\n",
    "# we also need to chnage so it takes 1 cahnnel instead of three channels\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features,NUM_CLASSES)\n",
    "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "print()\n",
    "print(resnet18.conv1)\n",
    "print(resnet18.fc)\n",
    "\n",
    "# Make sure to send our model to GPU if available\n",
    "resnet18 = resnet18.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare True Label w/ Predicted Label #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (model, data_loader, device):\n",
    "    model = model.to(device)\n",
    "    model = model.eval() # put the model to evaultion mode\n",
    "    \n",
    "    num_correct_prediction = 0\n",
    "    num_total_labels = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            probabilities = resnet18(inputs.to(DEVICE))\n",
    "            predicted_class = torch.argmax(probabilities, dim=1) # Class predicted by model\n",
    "            \n",
    "            num_total_labels += labels.size()[0]\n",
    "            num_correct_prediction += (predicted_class == labels).sum()\n",
    "\n",
    "    return num_correct_prediction/num_total_labels * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test w/o training ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_index, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "    inputs = inputs\n",
    "    labels = labels\n",
    "    break\n",
    "    \n",
    "\n",
    "    \n",
    "img = np.transpose(inputs[4], axes=(1, 2, 0))\n",
    "img = np.squeeze(img.numpy(), axis=2)\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show\n",
    "\n",
    "\n",
    "\n",
    "resnet18 = resnet18.eval()\n",
    "\n",
    "with torch.no_grad(): # Save Performance when evaluting or prediciting\n",
    "    probabilities = resnet18(inputs.to(DEVICE))\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "print(\"Predicted Num : {:d}\".format(predicted_class[4]))\n",
    "print(\"Actual Num : {:d}\".format(labels[4]))\n",
    "print(\"\\nTotal Accuracy on test data : {:.3f} %\".format(compute_accuracy(resnet18,test_loader,DEVICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model (model, data_loader, learning_rate, num_epochs, device):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epochs in range(num_epochs):\n",
    "        \n",
    "        print(\"EPOCH : {0}/{1}\".format(epochs+1,num_epochs))\n",
    "        print(\"-\"*30)\n",
    "        \n",
    "        # train first\n",
    "        model.train()\n",
    "        for batch_index, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)   \n",
    "             \n",
    "            probabilities = resnet18(inputs)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = nn.functional.cross_entropy(probabilities,labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            \n",
    "            if (batch_index % 50 == 0) :\n",
    "                print(\"BATCH : {:3d}/{:3d} | LOSS : {:.3f} \".format(batch_index,len(data_loader),loss))\n",
    "            \n",
    "        \n",
    "        # evalute\n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            accuracy = compute_accuracy(model,data_loader,DEVICE)\n",
    "            print(\"\\nTotal Accuracy On Training Data : {:.3f} %\".format(accuracy))\n",
    "        \n",
    "        # Save best weights\n",
    "        if (accuracy > best_accuracy):\n",
    "            best_accuracy = accuracy\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print(\"Elapsed Time : {:.0f} min {:.0f} sec\\n\".format((time.time() - start_time)/60 , (time.time() - start_time)%60)) \n",
    "    \n",
    "    print(\"\\nTotal Time : {:.0f} min {:.0f} sec\".format((time.time() - start_time)/60 , (time.time() - start_time)%60))\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = train_model(resnet18,train_loader,LEARNING_RATE,NUM_EPOCHS,DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test w/ Training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "features = torch.empty(0)\n",
    "true_label = torch.empty(0)\n",
    "\n",
    "for batch_index, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "    features = torch.cat((features,inputs))\n",
    "    true_label = torch.cat((true_label,labels))\n",
    "    \n",
    "img = np.transpose(features[0], axes=(1, 2, 0))\n",
    "img = np.squeeze(img.numpy(), axis=2)\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show\n",
    "\n",
    "\n",
    "resnet18 = resnet18.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    probabilities = resnet18(features.to(DEVICE))\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "print(\"Predicted Num : {:.0f}\".format(predicted_class[0]))\n",
    "print(\"Actual Num : {:.0f}\".format(true_label[0]))\n",
    "\n",
    "print(\"\\nTotal Accuracy on test data : {:.3f} %\".format(compute_accuracy(resnet18,test_loader,DEVICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "LABELS = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "true_label = true_label.to('cpu')\n",
    "predicted_label = predicted_class.to('cpu')\n",
    "\n",
    "cf_matrix = confusion_matrix(true_label,predicted_label)\n",
    "\n",
    "df = pd.DataFrame(cf_matrix, index = CLASSES, columns = CLASSES)\n",
    "\n",
    "print(\"\\nConfusion Matrix :-\")\n",
    "print(df.to_markdown())\n",
    "\n",
    "accuracy = accuracy_score(true_label,predicted_label)\n",
    "precison = precision_score(true_label,predicted_label,labels=LABELS,average='micro')\n",
    "recall = recall_score(true_label,predicted_label,labels=LABELS,average='micro')\n",
    "f_score = f1_score(true_label,predicted_label,labels=LABELS,average='micro')\n",
    "\n",
    "print (\"\\naccuray : {:0.3f} %\".format(accuracy*100))\n",
    "print (\"precison : {:0.3f}\".format(precison*100))\n",
    "print (\"recall : {:.3f}\".format(recall*100))\n",
    "print (\"f-score : {:.3f}\".format(f_score*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
